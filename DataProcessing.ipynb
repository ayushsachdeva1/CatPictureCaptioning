{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7de199f-309d-4e73-b6aa-29312bed57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torchtext\n",
    "import pandas, os, pickle\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from filelock import FileLock\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd89d3f-e194-42b1-8db9-8cf94f75b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image.\n",
    "def display_image(img):\n",
    "    plt.figure(); plt.imshow(img)\n",
    "    plt.grid(False);  plt.axis('off'); plt.show()\n",
    "\n",
    "def create_dataset(filenames: [], # location of the file.\n",
    "                  start = 0, \n",
    "                 count = 20,\n",
    "                 image_transform = None):\n",
    "  \n",
    "    cap_img = {}\n",
    "\n",
    "    for filename in filenames: \n",
    "\n",
    "        print('Loading %s ...\\n' % filename, end = '')\n",
    "\n",
    "        f = open(filename, 'r')\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        for i in range(start, min(len(json_data['annotations']), start + count)):\n",
    "\n",
    "            if (i%100 == 0):\n",
    "                print(i)\n",
    "\n",
    "            \n",
    "            image_data = json_data['annotations'][i]\n",
    "\n",
    "            try:\n",
    "                img = Image.open(BytesIO(requests.get(image_data[\"url\"]).content)).convert(\"RGB\")\n",
    "                if image_transform:\n",
    "                    img = image_transform(img) \n",
    "                cap_img[(image_data['caption'], image_data[\"url\"])] = img\n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            \n",
    "\n",
    "    return cap_img\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                 std = [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.RandomCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41c903c-2ef1-4f69-8c08-833f294859c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./redcaps_v1.0_annotations/annotations/catpictures_2018.json ...\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n"
     ]
    }
   ],
   "source": [
    "val_data = create_dataset(filenames = [\"./redcaps_v1.0_annotations/annotations/catpictures_2018.json\"], start = 0, count = 25000, image_transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccc7edd-b9d5-4c9e-b23f-2faec77faeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_data_new.pkl', 'wb') as fid:\n",
    "    pickle.dump(val_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8aaf04-f6e5-4a3d-8a5c-a5ed86aaae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('val_data_new.pkl', 'rb') as f:\n",
    "    temp_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551d503c-a65d-4329-92f4-793e1233348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6111"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d68ccd-5361-4d7a-93eb-466ee792d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for key in temp_data.keys():\n",
    "    data.append((key[0], key[1], temp_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0b00a6-c7e1-4ccf-8fd0-d7f451756ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/mmqzfsds2y7cshnj7f2np6fc0000gn/T/ipykernel_5684/175069178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'display_image' is not defined"
     ]
    }
   ],
   "source": [
    "display_image(Image.open(BytesIO(requests.get(data[0][1]).content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e2fcef-5023-42a7-b814-58667ad73ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_data_list.pkl', 'wb') as fid:\n",
    "    pickle.dump(data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b0ed41-8d84-489a-b4fc-8c876dbbb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "\n",
    "for i in range(0, len(data)//2):\n",
    "    small_data.append(data[i])\n",
    "\n",
    "with open('train_data_part1.pkl', 'wb') as fid:\n",
    "    pickle.dump(small_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dccb61be-7f4a-465d-888b-0ebb293115be",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "\n",
    "for i in range(len(data)//2, len(data)):\n",
    "    small_data.append(data[i])\n",
    "\n",
    "with open('train_data_part2.pkl', 'wb') as fid:\n",
    "    pickle.dump(small_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37628259-7e5e-4abe-9c0a-fae0c33609b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "\n",
    "for i in range(2*len(data)//5, 3*len(data)//5):\n",
    "    small_data.append(data[i])\n",
    "\n",
    "with open('train_data3.pkl', 'wb') as fid:\n",
    "    pickle.dump(small_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e346a5c-31c2-4abf-b6af-4283c0d23aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "\n",
    "for i in range(3*len(data)//5, 4*len(data)//5):\n",
    "    small_data.append(data[i])\n",
    "\n",
    "with open('train_data4.pkl', 'wb') as fid:\n",
    "    pickle.dump(small_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d20bc5ae-e549-40c8-bfcf-c7c8f7926656",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "\n",
    "for i in range(4*len(data)//5, len(data)):\n",
    "    small_data.append(data[i])\n",
    "\n",
    "with open('train_data5.pkl', 'wb') as fid:\n",
    "    pickle.dump(small_data, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfac77-e6e3-46db-b04f-5d024d9f8876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
